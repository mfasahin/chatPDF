import os
from dotenv import load_dotenv
from langchain_groq import ChatGroq

# 1. AyarlarÄ± YÃ¼kle
load_dotenv()
api_key = os.getenv("GROQ_API_KEY")

print("âš¡ Groq ile Ä±ÅŸÄ±k hÄ±zÄ±nda baÄŸlantÄ± deneniyor (Yeni Model)...")

if not api_key:
    print("âŒ HATA: .env dosyasÄ±nda GROQ_API_KEY bulunamadÄ±!")
    exit()

try:
    # 2. Modeli TanÄ±mla
    # GÃœNCELLEME: Eski model yerine en yeni "Llama-3.3-70b" kullanÄ±yoruz.
    # Bu model hem Ã§ok daha zeki hem de bedava.
    llm = ChatGroq(
        temperature=0, 
        groq_api_key=api_key, 
        model_name="llama-3.3-70b-versatile" 
    )

    # 3. Soru Sor
    soru = "YazÄ±lÄ±m Ã¶ÄŸrenen birine tek cÃ¼mlelik TÃ¼rkÃ§e tavsiye ver."
    print(f"â“ Soru: {soru}")
    
    cevap = llm.invoke(soru)
    
    print("\n--- ğŸš€ Modelin CevabÄ± ---")
    print(cevap.content)
    print("\nâœ… ZAFER! BaÄŸlantÄ± mÃ¼kemmel Ã§alÄ±ÅŸÄ±yor.")

except Exception as e:
    print(f"\nâŒ HATA: {e}")