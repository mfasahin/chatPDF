import streamlit as st
from PyPDF2 import PdfReader
import os
from dotenv import load_dotenv

# LangChain - GÃœNCEL ve DOÄRU IMPORTLAR
from langchain_groq import ChatGroq
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser


# 1. Sayfa AyarlarÄ±
st.set_page_config(page_title="PDF AsistanÄ±", page_icon="ğŸ¤–")
st.header("ğŸ¤– PDF Dosyanla Sohbet Et (Groq + Llama 3.3)")

# 2. API KontrolÃ¼
load_dotenv()
api_key = os.getenv("GROQ_API_KEY")

if not api_key:
    st.error("âŒ API AnahtarÄ± BulunamadÄ±! .env dosyanÄ± kontrol et.")
    st.stop()

# 3. Yan MenÃ¼ (Dosya YÃ¼kleme)
with st.sidebar:
    st.title("ğŸ“‚ PDF YÃ¼kle")
    pdf_dosyasi = st.file_uploader("DosyanÄ± buraya bÄ±rak", type="pdf")
    st.write("---")
    st.write("Model: Llama-3.3-70b (Groq)")

# 4. Ana AkÄ±ÅŸ
if pdf_dosyasi is not None:
    # --- A) PDF OKUMA ---
    pdf_okuyucu = PdfReader(pdf_dosyasi)
    metin = ""
    for sayfa in pdf_okuyucu.pages:
        yazi = sayfa.extract_text()
        if yazi:
            metin += yazi

    if len(metin) == 0:
        st.error("âš ï¸ Bu PDF'ten metin okunamadÄ±!")
    else:
        st.success(f"âœ… Dosya analiz edildi! ({len(metin)} karakter)")

        # --- B) METNÄ° PARÃ‡ALA ---
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
        chunks = text_splitter.split_text(metin)

        # --- C) EMBEDDING + FAISS ---
        embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2"
        )
        vectorstore = FAISS.from_texts(chunks, embeddings)

        # --- D) SORU ---
        st.write("---")
        soru = st.text_input(
            "Bu dokÃ¼man hakkÄ±nda ne bilmek istiyorsun?",
            placeholder="Ã–rn: Beowulf'taki pagan Ã¶geler nelerdir?"
        )

        if soru:
            with st.spinner("ğŸ§  DÃ¼ÅŸÃ¼nÃ¼yor..."):

                # LLM
                llm = ChatGroq(
                    model_name="llama-3.3-70b-versatile",
                    groq_api_key=api_key,
                    temperature=0.3
                )

                # PROMPT
                prompt = ChatPromptTemplate.from_template("""
AÅŸaÄŸÄ±daki baÄŸlamÄ± kullanarak soruyu cevapla.
EÄŸer cevap baÄŸlamda yoksa "Bu dokÃ¼manda buna dair bilgi yok." de.

BaÄŸlam:
{context}

Soru:
{question}
""")

                retriever = vectorstore.as_retriever(search_kwargs={"k": 4})

                # ğŸ”¥ MODERN RAG ZÄ°NCÄ°RÄ°
                chain = (
                    {
                        "context": retriever,
                        "question": RunnablePassthrough()
                    }
                    | prompt
                    | llm
                    | StrOutputParser()
                )

                cevap = chain.invoke(soru)

                st.markdown("### ğŸ¤– Cevap:")
                st.write(cevap)
